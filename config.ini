[global]
default_schema = baseline

[CDTB]
train = data/CDTB/train
test = data/CDTB/test
encoding = utf-8
;ctb = data/CDTB/CTB
;ctb_encoding = utf-8
cache = data/CDTB

[segmenter.svm]
seed = 21
clues = data/CDTB/connective_clues.txt
clues_encoding = utf-8
comma_candidate = ,，;；
model_dir = data/CDTB/models/segmenter_svm.model

[treebuilder.spinn]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn.model

[treebuilder.spinn_bow]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_bow.model

[treebuilder.spinn_bilstm]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
edu_rnn_encoder_size = 100
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_bilstm.model

[treebuilder.spinn_cnn]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
edu_cutoff = 30
position_embedding_size = 5
unigram_filter_num = 50
bigram_filter_num = 25
trigram_filter_num = 25
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_cnn.model
