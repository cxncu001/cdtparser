[global]
default_schema = baseline

[CDTB]
train = data/CDTB/train
test = data/CDTB/test
encoding = utf-8
;ctb = data/CDTB/CTB
;ctb_encoding = utf-8
cache = data/CDTB

[segmenter.svm]
seed = 21
clues = data/CDTB/connective_clues.txt
clues_encoding = utf-8
comma_candidate = ,，;；
model_dir = data/CDTB/models/segmenter_svm.model

[treebuilder.spinn]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn.model

[treebuilder.spinn_bow]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_bow.model

[treebuilder.spinn_bilstm]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
edu_rnn_encoder_size = 50
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_bilstm.model

[treebuilder.spinn_cnn]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
edu_cutoff = 30
position_embedding_size = 15
unigram_filter_num = 64
bigram_filter_num = 46
trigram_filter_num = 32
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_cnn.model

[treebuilder.spinn_lex]
seed = 21
num_epoch = 20
batch_size = 32
lr = 0.001
l2_penalty = 1e-5
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 15
hidden_size = 128
proj_dropout = 0.2
mlp_layers = 2
mlp_dropout = 0.2
eval_every = 8
model_dir = data/CDTB/models/treebuilder_spinn_lex.model

[treebuilder.stacklstm]
seed = 21
num_epoch = 10
batch_size = 1
lr = 0.001
l2_penalty = 1e-5
eval_every = 64
model_dir = data/CDTB/models/treebuilder_stacklstm.model
hidden_size = 100
lstm_layers = 2
lstm_dropout = 0.1
word_embedding = data/CDTB/CH.GigawordWiki.50.bin
pos_embedding_size = 50
relation_embedding_size = 50
action_embedding_size = 30
sentence_position_cutoff = 5
sentence_position_embedding_size = 25
edu_position_cutoff = 5
edu_position_embedding_size = 25
edu_length_cutoff = 50
edu_length_embedding_size = 50
